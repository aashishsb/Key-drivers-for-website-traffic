# -*- coding: utf-8 -*-
"""The Buttonwood Tree

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GJspuGEzFlpu1TXezJ8HEC8cII4zMJe8

# The Buttonwood Tree - The task in hand is to find out the key drivers responsible for the traffic in websites of different companies and their impact.

#01 Importing required packages
"""

# Installing required packages
! pip install pandas==0.25

# Installing required packages
# pip install pandas==0.25

# Importing the libraries
import numpy as np
import pandas as pd

import pandas_profiling as pp
from pandas_profiling import ProfileReport

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn import metrics
import xgboost as xg
from xgboost import plot_importance

from matplotlib import pyplot
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

"""#02 Importing the Dataset"""

# Importing the dataset
dataset = pd.read_csv('TBT Dataset .csv')

dataset.head()

"""#03 Data Exploration"""

dataset.info()

# Pandas Profiling
Profile = ProfileReport(dataset)
Profile

"""#04 Data Preprocessing"""

# Dropping columns with a lot of missing values
dataset.drop(columns=['investment','Company','acquisitions'], axis=1, inplace=True)
dataset.head()

dataset = dataset.fillna('Not available')

dataset.isnull().sum()

dataset = pd.get_dummies(dataset)

dataset.head()

"""#05 Test/Train Split"""

# Splitting the dataset into the Training set and Test set
y = dataset['website_hits']
X = dataset[['revenue','compitator_type_Direct',
       'compitator_type_Indirect', 'consumption_format_Text',
       'consumption_format_Video', 'target_segment _Business',
       'target_segment _Economy', 'target_segment _Finance',
       'target_segment _General', 'service_Banking', 'service_Digital Article',
       'service_Digital article', 'service_Digital article ',
       'service_Finance', 'service_Journal', 'service_Journal ',
       'service_Magazine', 'service_Newspaper', 'service_Newspaper ',
       'service_Television', 'service_Television ', 'service_Training',
       'keywords_Not available', 'keywords_WallStreetJournal',
       'keywords_aba bank', 'keywords_amazon', 'keywords_b of a',
       'keywords_bank of america transfer limit', 'keywords_bitcoin halving',
       'keywords_biz tv', 'keywords_bnn', 'keywords_cheddar',
       'keywords_financial brand', 'keywords_fox news',
       'keywords_google flights', 'keywords_harshad mehta',
       'keywords_mary g. ross', 'keywords_mlb standings', 'keywords_mt940',
       'keywords_nbc news', 'keywords_new ork times',
       'keywords_nuro kroger grocery delivery', 'keywords_pehub',
       'keywords_private equity international', 'keywords_reuters',
       'keywords_routing number', 'keywords_sky news', 'keywords_stripe ipo',
       'keywords_the economist', 'keywords_usd to inr',
       'keywords_venture cpitalist', 'keywords_washington post',
       'keywords_wells fargo', 'keywords_wellsfargo', 'country_Australia',
       'country_Canada ', 'country_Germany', 'country_India',
       'country_Portugal ', 'country_UK ', 'country_USA']]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""#06 Running Multiple Regression Models

###06.01 Running Random Forest Regressor
"""

# Training the Random Forest Regression model 
regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)
regressor.fit(X, y)

# Predicting a new result
y_pred=regressor.predict(X_test)

# Model Performance Measurement
r2 = r2_score(y_train, regressor.predict(X_train))

#perm_imp_rfpimp = permutation_importance(regressor, X_train, y_train, r2)
print('R^2 value:{}'.format(r2))
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

# Calculating Feature Importance
importance1=regressor.feature_importances_
sorted_indices = np.sort(importance1)
columns= X.columns
figure(figsize=(15, 25))
plt.barh(columns, sorted_indices)
plt.title('Feature Importance')
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')

"""###06.02 Running Xgboost Regressor """

# Creating an Xgboost Model
xgb_r = xg.XGBRegressor(objective ='reg:linear',
                  n_estimators = 10, seed = 123)
xgb_r.fit(X_train, y_train)

# Predicting result
pred = xgb_r.predict(X_test)

# Model Perfrmance Measurement
r21 = r2_score(y_train, xgb_r.predict(X_train))

print('R^2 value:{}'.format(r21))
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, pred)))

# Calculating feature Importance
xgb_r.feature_importances_
plot_importance(xgb_r)
pyplot.show()